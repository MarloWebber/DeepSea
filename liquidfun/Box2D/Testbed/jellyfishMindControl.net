FANN_FLO_2.1
num_layers=4
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=5 5 6 6 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (5, 5, 5.00000000000000000000e-01) (5, 5, 5.00000000000000000000e-01) (5, 5, 5.00000000000000000000e-01) (5, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) (5, 5, 5.00000000000000000000e-01) (5, 5, 5.00000000000000000000e-01) (5, 5, 5.00000000000000000000e-01) (5, 5, 5.00000000000000000000e-01) (5, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) (6, 5, 5.00000000000000000000e-01) (6, 5, 5.00000000000000000000e-01) (6, 5, 5.00000000000000000000e-01) (6, 5, 5.00000000000000000000e-01) (6, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -4.63454909622669219971e-02) (1, 5.16011342406272888184e-02) (2, -3.72335761785507202148e-02) (3, 1.41509994864463806152e-02) (4, 2.66633704304695129395e-02) (0, -2.65953168272972106934e-02) (1, 2.21493691205978393555e-02) (2, 2.48716026544570922852e-03) (3, -3.30609679222106933594e-02) (4, -6.47831708192825317383e-03) (0, -8.96379351615905761719e-04) (1, 8.56086611747741699219e-04) (2, 2.20582038164138793945e-02) (3, -3.46716120839118957520e-02) (4, 3.36640402674674987793e-02) (0, 3.63818183541297912598e-02) (1, -9.64894294738769531250e-02) (2, -7.29269161820411682129e-02) (3, -7.33012333512306213379e-02) (4, 6.67392536997795104980e-02) (5, -3.61255109310150146484e-02) (6, 2.60636880993843078613e-02) (7, 6.34595230221748352051e-02) (8, 5.13466075062751770020e-02) (9, 3.44573929905891418457e-02) (5, -8.79888236522674560547e-03) (6, -9.30564105510711669922e-02) (7, 5.56314811110496520996e-02) (8, 6.40602931380271911621e-02) (9, -8.82933586835861206055e-02) (5, -1.74546986818313598633e-02) (6, -8.22851881384849548340e-02) (7, 6.33077695965766906738e-02) (8, 4.53117266297340393066e-02) (9, 3.18658128380775451660e-02) (5, -1.00288465619087219238e-02) (6, -8.12835916876792907715e-02) (7, -4.59848158061504364014e-02) (8, 9.24583151936531066895e-02) (9, -1.43445581197738647461e-02) (5, 4.75368574261665344238e-02) (6, -8.43807309865951538086e-03) (7, 8.65115299820899963379e-02) (8, -3.04049327969551086426e-02) (9, 5.68903163075447082520e-02) (10, 2.01755613088607788086e-02) (11, -9.40231084823608398438e-02) (12, 6.04008957743644714355e-02) (13, 4.72486540675163269043e-02) (14, -6.73243403434753417969e-02) (15, 2.71401479840278625488e-02) (10, -8.88768658041954040527e-02) (11, 5.87393566966056823730e-02) (12, -9.40033048391342163086e-03) (13, 6.24697282910346984863e-02) (14, -6.80325180292129516602e-03) (15, 8.18007960915565490723e-02) (10, 6.94133266806602478027e-02) (11, -5.11717647314071655273e-02) (12, 4.58610877394676208496e-02) (13, 8.11199620366096496582e-02) (14, 3.13735380768775939941e-02) (15, 6.35759010910987854004e-02) (10, 4.44277450442314147949e-02) (11, -2.33147367835044860840e-02) (12, -4.55829501152038574219e-03) (13, -6.56011030077934265137e-02) (14, -4.59833443164825439453e-03) (15, 4.94568869471549987793e-02) (10, -7.31427967548370361328e-02) (11, 8.10571089386940002441e-02) (12, -3.00624966621398925781e-03) (13, 1.84191316366195678711e-02) (14, 6.75686374306678771973e-02) (15, 6.65888264775276184082e-02) 
